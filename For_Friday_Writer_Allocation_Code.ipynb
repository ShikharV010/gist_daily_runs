{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShikharV010/gist_daily_runs/blob/main/For_Friday_Writer_Allocation_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UsvZ4dXSPoo",
        "outputId": "5b4f26f8-406a-4daa-cfd9-b37e9b60c4da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Campaign Writer Assignment Extractor ===\n",
            "Loading data from Google Sheets...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2-1575413932.py:26: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Active Product campaigns: 131\n",
            "Running optimization...\n",
            "Optimization setup: 68 writers and 131 campaigns\n",
            "Campaign 0351b0fe-1ee7-4d78-827d-8c08e33a0b86 is First Time Cycle - applying 20x priority multiplier\n",
            "Campaign 384c5612-722b-43d8-95c9-2c50247c6a93 is First Time Cycle - applying 20x priority multiplier\n",
            "Campaign 5f2ed42c-58e8-402e-8d8c-aff56b958c6b is First Time Cycle - applying 20x priority multiplier\n",
            "Campaign 61f708d1-7421-4ffb-a3be-0967aa4b072c is First Time Cycle - applying 20x priority multiplier\n",
            "Campaign 72663ba7-3e84-4204-a72f-7fce50607eea is First Time Cycle - applying 20x priority multiplier\n",
            "Campaign 80612b3f-ea4b-4bd7-99b7-37a1421fafc1 is First Time Cycle - applying 20x priority multiplier\n",
            "Campaign 89349814-59d2-477c-8b56-9c9d471e7f9e is First Time Cycle - applying 20x priority multiplier\n",
            "Campaign a8998f69-bb75-4b2e-9d80-5e9815533ecb is First Time Cycle - applying 20x priority multiplier\n",
            "Campaign b4154640-a977-4927-8bd0-932154cfca90 is First Time Cycle - applying 20x priority multiplier\n",
            "Campaign b439f3cf-5b49-455b-b9e5-5f1c90f34772 is First Time Cycle - applying 20x priority multiplier\n",
            "Campaign be966cd9-ba2f-4ef9-b435-2a2a9728b49f is First Time Cycle - applying 20x priority multiplier\n",
            "Campaign e29c6a96-66e9-4fee-9dff-bc16172669e6 is First Time Cycle - applying 20x priority multiplier\n",
            "Solving optimization problem...\n",
            "Optimization problem solved successfully\n",
            "Created 140 writer-campaign assignments\n",
            "Total articles assigned: 680\n",
            "First Time Cycle assignments: 20 assignments, 115 articles\n",
            "\n",
            "=== ASSIGNMENT RESULTS ===\n",
            "DataFrame ready for PostgreSQL insertion:\n",
            "Shape: (140, 11)\n",
            "\n",
            "Column types:\n",
            "campaign_id                    object\n",
            "campaign_url                   object\n",
            "writer_id                      object\n",
            "weekly_target                   int64\n",
            "is_faced_writer                  bool\n",
            "is_first_time_cycle              bool\n",
            "context_score                  object\n",
            "next_billing_date              object\n",
            "assignment_date                object\n",
            "created_at             datetime64[ns]\n",
            "updated_at             datetime64[ns]\n",
            "dtype: object\n",
            "\n",
            "First 5 rows:\n",
            "                            campaign_id        campaign_url  \\\n",
            "0  02344b65-6cd1-401c-89be-d69221aa428e         gushwork.ai   \n",
            "1  89b8e99d-0c24-4864-b4b6-c87a817e08b4          pazago.com   \n",
            "2  3725b2fe-1635-438f-b414-3c5215aa4756  theschoolhouse.org   \n",
            "3  a8998f69-bb75-4b2e-9d80-5e9815533ecb       wiz-team.com/   \n",
            "4  632d960d-46c9-42f7-8049-b47e8b610da2             wedd.ai   \n",
            "\n",
            "                      writer_id  weekly_target  is_faced_writer  \\\n",
            "0      arfa.hussain@gushwork.ai              3             True   \n",
            "1      arfa.hussain@gushwork.ai              7             True   \n",
            "2      shreya.ghosh@gushwork.ai             10             True   \n",
            "3         aqsa.shad@gushwork.ai             10             True   \n",
            "4  thushara.premdas@gushwork.ai              3             True   \n",
            "\n",
            "   is_first_time_cycle context_score next_billing_date assignment_date  \\\n",
            "0                False          None        2025-07-09      2025-06-19   \n",
            "1                False          None        2025-06-28      2025-06-19   \n",
            "2                False          None        2025-07-21      2025-06-19   \n",
            "3                 True          None        2025-07-13      2025-06-19   \n",
            "4                False          None        2025-07-09      2025-06-19   \n",
            "\n",
            "                  created_at                 updated_at  \n",
            "0 2025-06-19 07:18:59.602897 2025-06-19 07:18:59.602897  \n",
            "1 2025-06-19 07:18:59.602897 2025-06-19 07:18:59.602897  \n",
            "2 2025-06-19 07:18:59.602897 2025-06-19 07:18:59.602897  \n",
            "3 2025-06-19 07:18:59.602897 2025-06-19 07:18:59.602897  \n",
            "4 2025-06-19 07:18:59.602897 2025-06-19 07:18:59.602897  \n",
            "\n",
            "Sample of all columns:\n",
            "campaign_id: 02344b65-6cd1-401c-89be-d69221aa428e\n",
            "campaign_url: gushwork.ai\n",
            "writer_id: arfa.hussain@gushwork.ai\n",
            "weekly_target: 3\n",
            "is_faced_writer: True\n",
            "is_first_time_cycle: False\n",
            "context_score: None\n",
            "next_billing_date: 2025-07-09\n",
            "assignment_date: 2025-06-19\n",
            "created_at: 2025-06-19 07:18:59.602897\n",
            "updated_at: 2025-06-19 07:18:59.602897\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ortools.linear_solver import pywraplp\n",
        "from datetime import datetime\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "\n",
        "def standardize_writer_ids(df, id_column='Writer ID'):\n",
        "    \"\"\"Convert writer IDs to lowercase strings for consistency\"\"\"\n",
        "    if id_column in df.columns:\n",
        "        df[id_column] = df[id_column].astype(str).str.lower()\n",
        "    return df\n",
        "\n",
        "def read_google_sheet(gc, spreadsheet_id, sheet_name=0):\n",
        "    \"\"\"Read a Google Sheet into a pandas DataFrame\"\"\"\n",
        "    try:\n",
        "        spreadsheet = gc.open_by_key(spreadsheet_id)\n",
        "        worksheet = spreadsheet.get_worksheet(sheet_name) if isinstance(sheet_name, int) else spreadsheet.worksheet(sheet_name)\n",
        "        data = worksheet.get_all_values()\n",
        "        if not data:\n",
        "            return pd.DataFrame()\n",
        "        df = pd.DataFrame(data[1:], columns=data[0])\n",
        "        for col in df.columns:\n",
        "            try:\n",
        "                df[col] = pd.to_numeric(df[col], errors='ignore')\n",
        "            except:\n",
        "                pass\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading Google Sheet: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def get_campaign_priority_weights(contracted_approved_df):\n",
        "    \"\"\"Calculate weights based on billing date proximity and First Time Cycle status\"\"\"\n",
        "    priority_weights = {}\n",
        "    today = datetime.now().replace(tzinfo=None)\n",
        "\n",
        "    for _, campaign_row in contracted_approved_df.iterrows():\n",
        "        campaign = campaign_row['Campaign ID']\n",
        "        base_weight = 1.0\n",
        "\n",
        "        # Check if this is a First Time Cycle campaign\n",
        "        is_first_time = False\n",
        "        if 'First Time Cycle' in campaign_row:\n",
        "            first_time_value = str(campaign_row['First Time Cycle']).strip().lower()\n",
        "            is_first_time = first_time_value in ['yes', 'true', '1']\n",
        "\n",
        "        if is_first_time:\n",
        "            base_weight *= 20.0\n",
        "            print(f\"Campaign {campaign} is First Time Cycle - applying 20x priority multiplier\")\n",
        "\n",
        "        # Billing date logic\n",
        "        if 'Next Billing Date' not in campaign_row:\n",
        "            priority_weights[campaign] = base_weight\n",
        "            continue\n",
        "\n",
        "        billing_date_str = campaign_row['Next Billing Date']\n",
        "        if pd.isna(billing_date_str) or not billing_date_str:\n",
        "            priority_weights[campaign] = base_weight\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            billing_date = pd.to_datetime(billing_date_str).replace(tzinfo=None)\n",
        "        except:\n",
        "            try:\n",
        "                billing_date = datetime.strptime(billing_date_str, '%m/%d/%Y')\n",
        "            except:\n",
        "                try:\n",
        "                    billing_date = datetime.strptime(billing_date_str, '%Y-%m-%d')\n",
        "                except:\n",
        "                    priority_weights[campaign] = base_weight\n",
        "                    continue\n",
        "\n",
        "        days_until_billing = (billing_date - today).days\n",
        "        billing_multiplier = 1.0\n",
        "        if days_until_billing <= 0:\n",
        "            billing_multiplier = 10.0\n",
        "        elif days_until_billing <= 7:\n",
        "            billing_multiplier = 8.0\n",
        "        elif days_until_billing <= 14:\n",
        "            billing_multiplier = 5.0\n",
        "        elif days_until_billing <= 30:\n",
        "            billing_multiplier = 3.0\n",
        "\n",
        "        priority_weights[campaign] = base_weight * billing_multiplier\n",
        "\n",
        "    return priority_weights\n",
        "\n",
        "def optimize_writer_assignments(contracted_approved_df, campaign_writer_df, writer_capacity_df):\n",
        "    \"\"\"\n",
        "    Optimize writer assignments and return a clean DataFrame for PostgreSQL insertion\n",
        "    \"\"\"\n",
        "    # Create solver\n",
        "    solver = pywraplp.Solver.CreateSolver('SCIP')\n",
        "    if not solver:\n",
        "        return None, \"Could not create solver.\"\n",
        "\n",
        "    # Get unique writers and campaigns\n",
        "    writers = writer_capacity_df['Writer ID'].unique()\n",
        "    campaigns = contracted_approved_df['Campaign ID'].unique()\n",
        "\n",
        "    print(f\"Optimization setup: {len(writers)} writers and {len(campaigns)} campaigns\")\n",
        "\n",
        "    if len(writers) == 0 or len(campaigns) == 0:\n",
        "        return None, \"No writers or campaigns found.\"\n",
        "\n",
        "    # Get priority weights\n",
        "    priority_weights = get_campaign_priority_weights(contracted_approved_df)\n",
        "\n",
        "    # Identify First Time Cycle campaigns\n",
        "    first_time_campaigns = []\n",
        "    first_time_targets = {}\n",
        "\n",
        "    for _, campaign_row in contracted_approved_df.iterrows():\n",
        "        campaign = campaign_row['Campaign ID']\n",
        "        if 'First Time Cycle' in campaign_row:\n",
        "            first_time_value = str(campaign_row['First Time Cycle']).strip().lower()\n",
        "            if first_time_value in ['yes', 'true', '1']:\n",
        "                first_time_campaigns.append(campaign)\n",
        "                outstanding = campaign_row['Outstanding on day'] if 'Outstanding on day' in campaign_row else 0\n",
        "                topics_approved = campaign_row['Topics Approved'] if 'Topics Approved' in campaign_row else 0\n",
        "\n",
        "                if pd.notna(outstanding) and pd.notna(topics_approved) and topics_approved > 0:\n",
        "                    assignable_content = min(outstanding, topics_approved)\n",
        "                    target = min(13, int(assignable_content / 2.5))\n",
        "                    first_time_targets[campaign] = target\n",
        "                elif pd.notna(topics_approved) and topics_approved > 0:\n",
        "                    first_time_targets[campaign] = 10\n",
        "\n",
        "    # Article count variables\n",
        "    article_count = {}\n",
        "    for writer in writers:\n",
        "        for campaign in campaigns:\n",
        "            article_count[(writer, campaign)] = solver.IntVar(0, 1000, f'count_{writer}_{campaign}')\n",
        "\n",
        "    # Writer capacity constraints\n",
        "    for writer in writers:\n",
        "        writer_capacity_rows = writer_capacity_df[writer_capacity_df['Writer ID'] == writer]\n",
        "        if writer_capacity_rows.empty:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            writer_weekly_capacity = writer_capacity_rows['Weekly Capacity'].iloc[0]\n",
        "            if pd.isna(writer_weekly_capacity):\n",
        "                writer_weekly_capacity = 1\n",
        "        except IndexError:\n",
        "            writer_weekly_capacity = 1\n",
        "\n",
        "        solver.Add(\n",
        "            sum(article_count[(writer, campaign)] for campaign in campaigns) <= writer_weekly_capacity\n",
        "        )\n",
        "\n",
        "    # Campaign constraints\n",
        "    for campaign in campaigns:\n",
        "        campaign_rows = contracted_approved_df[contracted_approved_df['Campaign ID'] == campaign]\n",
        "        if not campaign_rows.empty:\n",
        "            outstanding = campaign_rows['Outstanding on day'].fillna(0).iloc[0]\n",
        "            topics_approved = campaign_rows['Topics Approved'].fillna(0).iloc[0]\n",
        "\n",
        "            if topics_approved <= 0:\n",
        "                assignable_content = 0\n",
        "            else:\n",
        "                assignable_content = min(outstanding, topics_approved)\n",
        "\n",
        "            if assignable_content > 0:\n",
        "                solver.Add(\n",
        "                    sum(article_count[(writer, campaign)] for writer in writers) <= assignable_content\n",
        "                )\n",
        "\n",
        "                if campaign in first_time_campaigns and campaign in first_time_targets:\n",
        "                    min_required = first_time_targets[campaign]\n",
        "                    solver.Add(\n",
        "                        sum(article_count[(writer, campaign)] for writer in writers) >= min_required\n",
        "                    )\n",
        "                else:\n",
        "                    solver.Add(\n",
        "                        sum(article_count[(writer, campaign)] for writer in writers) >= min(3, assignable_content)\n",
        "                    )\n",
        "            else:\n",
        "                for writer in writers:\n",
        "                    solver.Add(article_count[(writer, campaign)] == 0)\n",
        "\n",
        "    # Find faced writer column\n",
        "    faced_writer_col = None\n",
        "    for col in campaign_writer_df.columns:\n",
        "        if 'faced' in col.lower() and 'writer' in col.lower():\n",
        "            faced_writer_col = col\n",
        "            break\n",
        "\n",
        "    if not faced_writer_col:\n",
        "        faced_writer_col = 'Faced Writer'\n",
        "        if faced_writer_col not in campaign_writer_df.columns:\n",
        "            campaign_writer_df[faced_writer_col] = False\n",
        "\n",
        "    # Objective function\n",
        "    objective = solver.Objective()\n",
        "    faced_writer_weight = 15\n",
        "    context_weight = 10\n",
        "\n",
        "    for writer in writers:\n",
        "        for campaign in campaigns:\n",
        "            base_weight = 0.1\n",
        "\n",
        "            context_row = campaign_writer_df[\n",
        "                (campaign_writer_df['Writer ID'].str.lower() == str(writer).lower()) &\n",
        "                (campaign_writer_df['Campaign ID'] == campaign)\n",
        "            ]\n",
        "\n",
        "            if not context_row.empty:\n",
        "                base_weight = 1.0\n",
        "\n",
        "                if faced_writer_col in context_row.columns:\n",
        "                    try:\n",
        "                        faced_value = context_row.iloc[0][faced_writer_col]\n",
        "                        if isinstance(faced_value, str):\n",
        "                            faced_writer = faced_value.lower() == 'true'\n",
        "                        else:\n",
        "                            faced_writer = bool(faced_value)\n",
        "\n",
        "                        if faced_writer:\n",
        "                            base_weight *= faced_writer_weight\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                if 'Context Score' in context_row.columns:\n",
        "                    try:\n",
        "                        context_score = context_row.iloc[0]['Context Score']\n",
        "                        if pd.notna(context_score):\n",
        "                            base_weight *= (1 + float(context_score) * context_weight)\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "            base_weight *= priority_weights.get(campaign, 1.0)\n",
        "            objective.SetCoefficient(article_count[(writer, campaign)], base_weight)\n",
        "\n",
        "    objective.SetMaximization()\n",
        "\n",
        "    # Solve\n",
        "    print(\"Solving optimization problem...\")\n",
        "    status = solver.Solve()\n",
        "\n",
        "    if status != pywraplp.Solver.OPTIMAL:\n",
        "        error_message = \"The problem is infeasible.\" if status == pywraplp.Solver.INFEASIBLE else f\"Optimization failed with status code: {status}\"\n",
        "        return None, error_message\n",
        "\n",
        "    print(\"Optimization problem solved successfully\")\n",
        "\n",
        "    # Collect results for PostgreSQL\n",
        "    assignments = []\n",
        "    current_time = datetime.now()\n",
        "\n",
        "    for writer in writers:\n",
        "        for campaign in campaigns:\n",
        "            count_value = article_count[(writer, campaign)].solution_value()\n",
        "\n",
        "            if count_value > 0:\n",
        "                count_value = int(count_value)\n",
        "\n",
        "                # Get campaign data\n",
        "                campaign_data = contracted_approved_df[contracted_approved_df['Campaign ID'] == campaign]\n",
        "\n",
        "                # Get writer-campaign relationship data\n",
        "                context_row = campaign_writer_df[\n",
        "                    (campaign_writer_df['Writer ID'].str.lower() == str(writer).lower()) &\n",
        "                    (campaign_writer_df['Campaign ID'] == campaign)\n",
        "                ]\n",
        "\n",
        "                # Extract relevant data\n",
        "                campaign_url = \"\"\n",
        "                next_billing_date = None\n",
        "                is_first_time_cycle = False\n",
        "                faced_writer = False\n",
        "                context_score = None\n",
        "\n",
        "                if not campaign_data.empty:\n",
        "                    if 'URL' in campaign_data.columns:\n",
        "                        campaign_url = campaign_data['URL'].iloc[0] if pd.notna(campaign_data['URL'].iloc[0]) else \"\"\n",
        "\n",
        "                    if 'Next Billing Date' in campaign_data.columns:\n",
        "                        billing_date_str = campaign_data['Next Billing Date'].iloc[0]\n",
        "                        if pd.notna(billing_date_str) and billing_date_str:\n",
        "                            try:\n",
        "                                next_billing_date = pd.to_datetime(billing_date_str).date()\n",
        "                            except:\n",
        "                                next_billing_date = None\n",
        "\n",
        "                    if 'First Time Cycle' in campaign_data.columns:\n",
        "                        first_time_value = str(campaign_data['First Time Cycle'].iloc[0]).strip().lower()\n",
        "                        is_first_time_cycle = first_time_value in ['yes', 'true', '1']\n",
        "\n",
        "                if not context_row.empty:\n",
        "                    if faced_writer_col in context_row.columns:\n",
        "                        try:\n",
        "                            faced_value = context_row.iloc[0][faced_writer_col]\n",
        "                            faced_writer = bool(faced_value)\n",
        "                        except:\n",
        "                            faced_writer = False\n",
        "\n",
        "                    if 'Context Score' in context_row.columns:\n",
        "                        try:\n",
        "                            context_score = float(context_row.iloc[0]['Context Score'])\n",
        "                        except:\n",
        "                            context_score = None\n",
        "\n",
        "                # Create assignment record\n",
        "                assignment = {\n",
        "                    'campaign_id': campaign,\n",
        "                    'campaign_url': campaign_url,\n",
        "                    'writer_id': writer,\n",
        "                    'weekly_target': count_value,\n",
        "                    'is_faced_writer': faced_writer,\n",
        "                    'is_first_time_cycle': is_first_time_cycle,\n",
        "                    'context_score': context_score,\n",
        "                    'next_billing_date': next_billing_date,\n",
        "                    'assignment_date': current_time.date(),\n",
        "                    'created_at': current_time,\n",
        "                    'updated_at': current_time\n",
        "                }\n",
        "\n",
        "                assignments.append(assignment)\n",
        "\n",
        "    # Create DataFrame\n",
        "    assignments_df = pd.DataFrame(assignments)\n",
        "\n",
        "    print(f\"Created {len(assignments_df)} writer-campaign assignments\")\n",
        "    if not assignments_df.empty:\n",
        "        print(f\"Total articles assigned: {assignments_df['weekly_target'].sum()}\")\n",
        "\n",
        "        # Print summary by campaign type\n",
        "        first_time_assignments = assignments_df[assignments_df['is_first_time_cycle'] == True]\n",
        "        if not first_time_assignments.empty:\n",
        "            print(f\"First Time Cycle assignments: {len(first_time_assignments)} assignments, {first_time_assignments['weekly_target'].sum()} articles\")\n",
        "\n",
        "    return assignments_df, \"\"\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the writer assignment optimization\"\"\"\n",
        "    print(\"=== Campaign Writer Assignment Extractor ===\")\n",
        "\n",
        "    # Authenticate with Google\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = default()\n",
        "    gc = gspread.authorize(creds)\n",
        "\n",
        "    # Sheet IDs\n",
        "    contracted_approved_sheet_id = '1YI5zepmJO4ci6qZVpBsSgcQFKTRGrijqS_ueGOXh8WQ'\n",
        "    context_table_sheet_id = '1rYhyoTTdvyvuZDdYytmoEtQJRVSo5XLJv9xCwHOcd8s'\n",
        "    writer_capacity_sheet_id = '1QPGzI73Ma0qbsbBpiucsJSX2ikmY_i4FKqIJ9OnWFw0'\n",
        "\n",
        "    print(\"Loading data from Google Sheets...\")\n",
        "\n",
        "    # Load data\n",
        "    contracted_approved_df = read_google_sheet(gc, contracted_approved_sheet_id)\n",
        "    campaign_writer_df = read_google_sheet(gc, context_table_sheet_id)\n",
        "    writer_capacity_df = read_google_sheet(gc, writer_capacity_sheet_id)\n",
        "\n",
        "    # Standardize writer IDs\n",
        "    campaign_writer_df = standardize_writer_ids(campaign_writer_df)\n",
        "    writer_capacity_df = standardize_writer_ids(writer_capacity_df)\n",
        "\n",
        "    # Filter for active campaigns (if Status and Type columns exist)\n",
        "    if 'Status' in contracted_approved_df.columns and 'Type' in contracted_approved_df.columns:\n",
        "        contracted_approved_df = contracted_approved_df[\n",
        "            (contracted_approved_df['Status'] == 'Active') &\n",
        "            (contracted_approved_df['Type'] == 'Product')\n",
        "        ]\n",
        "        print(f\"Active Product campaigns: {len(contracted_approved_df)}\")\n",
        "\n",
        "    # Add missing columns if needed\n",
        "    required_columns = ['Campaign ID', 'URL', 'Topics Approved', 'Outstanding on day', 'Next Billing Date', 'First Time Cycle']\n",
        "    for col in required_columns:\n",
        "        if col not in contracted_approved_df.columns:\n",
        "            if col in ['Next Billing Date', 'URL']:\n",
        "                contracted_approved_df[col] = \"\"\n",
        "            elif col == 'First Time Cycle':\n",
        "                contracted_approved_df[col] = \"No\"\n",
        "            else:\n",
        "                contracted_approved_df[col] = 0\n",
        "\n",
        "    # Convert numeric columns\n",
        "    for col in ['Topics Approved', 'Outstanding on day']:\n",
        "        if col in contracted_approved_df.columns:\n",
        "            contracted_approved_df[col] = pd.to_numeric(contracted_approved_df[col], errors='coerce').fillna(0)\n",
        "\n",
        "    # Filter for active writers\n",
        "    active_writer_capacity_df = writer_capacity_df[writer_capacity_df['Weekly Capacity'] > 0].copy()\n",
        "\n",
        "    # Run optimization\n",
        "    print(\"Running optimization...\")\n",
        "    assignments_df, error_message = optimize_writer_assignments(\n",
        "        contracted_approved_df,\n",
        "        campaign_writer_df,\n",
        "        active_writer_capacity_df\n",
        "    )\n",
        "\n",
        "    if assignments_df is not None and not assignments_df.empty:\n",
        "        print(\"\\n=== ASSIGNMENT RESULTS ===\")\n",
        "        print(\"DataFrame ready for PostgreSQL insertion:\")\n",
        "        print(f\"Shape: {assignments_df.shape}\")\n",
        "        print(\"\\nColumn types:\")\n",
        "        print(assignments_df.dtypes)\n",
        "        print(\"\\nFirst 5 rows:\")\n",
        "        print(assignments_df.head())\n",
        "        print(\"\\nSample of all columns:\")\n",
        "        for col in assignments_df.columns:\n",
        "            print(f\"{col}: {assignments_df[col].iloc[0] if len(assignments_df) > 0 else 'N/A'}\")\n",
        "\n",
        "        return assignments_df\n",
        "    else:\n",
        "        print(f\"ERROR: {error_message}\")\n",
        "        return None\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    result_df = main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ortools.linear_solver import pywraplp\n",
        "from datetime import datetime\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import psycopg2\n",
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "# PostgreSQL connection\n",
        "pg_params = {\n",
        "    'host': 'gw-postgres-dev.celzx4qnlkfp.us-east-1.rds.amazonaws.com',\n",
        "    'database': 'gw_prod',\n",
        "    'user': 'airbyte_user',\n",
        "    'password': 'airbyte_user_password',\n",
        "    'port': '5432'\n",
        "}\n",
        "\n",
        "def read_postgres_table(table_name):\n",
        "    \"\"\"Read data from PostgreSQL table\"\"\"\n",
        "    try:\n",
        "        engine = create_engine(f\"postgresql://{pg_params['user']}:{pg_params['password']}@{pg_params['host']}:{pg_params['port']}/{pg_params['database']}\")\n",
        "        df = pd.read_sql(f\"SELECT * FROM {table_name}\", engine)\n",
        "        engine.dispose()\n",
        "        print(f\"✅ Loaded {len(df)} records from {table_name}\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error reading {table_name}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def read_google_sheet(gc, spreadsheet_id, sheet_name=0):\n",
        "    \"\"\"Read a Google Sheet into a pandas DataFrame\"\"\"\n",
        "    try:\n",
        "        spreadsheet = gc.open_by_key(spreadsheet_id)\n",
        "        worksheet = spreadsheet.get_worksheet(sheet_name) if isinstance(sheet_name, int) else spreadsheet.worksheet(sheet_name)\n",
        "        data = worksheet.get_all_values()\n",
        "        if not data:\n",
        "            return pd.DataFrame()\n",
        "        df = pd.DataFrame(data[1:], columns=data[0])\n",
        "        for col in df.columns:\n",
        "            try:\n",
        "                df[col] = pd.to_numeric(df[col], errors='ignore')\n",
        "            except:\n",
        "                pass\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading Google Sheet: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def get_campaign_priority_weights(contracted_approved_df):\n",
        "    \"\"\"Calculate weights based on billing date proximity and First Time Cycle status\"\"\"\n",
        "    priority_weights = {}\n",
        "    today = datetime.now().replace(tzinfo=None)\n",
        "\n",
        "    for _, campaign_row in contracted_approved_df.iterrows():\n",
        "        campaign = campaign_row['Campaign ID']\n",
        "        base_weight = 1.0\n",
        "\n",
        "        # First Time Cycle gets 20x priority\n",
        "        if 'First Time Cycle' in campaign_row:\n",
        "            first_time_value = str(campaign_row['First Time Cycle']).strip().lower()\n",
        "            if first_time_value in ['yes', 'true', '1']:\n",
        "                base_weight *= 20.0\n",
        "                print(f\"Campaign {campaign} is First Time Cycle - applying 20x priority\")\n",
        "\n",
        "        # Billing date proximity weights\n",
        "        if 'Next Billing Date' in campaign_row:\n",
        "            billing_date_str = campaign_row['Next Billing Date']\n",
        "            if pd.notna(billing_date_str) and billing_date_str:\n",
        "                try:\n",
        "                    billing_date = pd.to_datetime(billing_date_str).replace(tzinfo=None)\n",
        "                    days_until_billing = (billing_date - today).days\n",
        "\n",
        "                    if days_until_billing <= 0:\n",
        "                        base_weight *= 10.0\n",
        "                    elif days_until_billing <= 7:\n",
        "                        base_weight *= 8.0\n",
        "                    elif days_until_billing <= 14:\n",
        "                        base_weight *= 5.0\n",
        "                    elif days_until_billing <= 30:\n",
        "                        base_weight *= 3.0\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "        priority_weights[campaign] = base_weight\n",
        "    return priority_weights\n",
        "\n",
        "def optimize_writer_assignments(contracted_approved_df, campaign_writer_df, writer_capacity_df):\n",
        "    \"\"\"Optimize writer assignments and return a clean DataFrame for PostgreSQL insertion\"\"\"\n",
        "    solver = pywraplp.Solver.CreateSolver('SCIP')\n",
        "    if not solver:\n",
        "        return None, \"Could not create solver.\"\n",
        "\n",
        "    writers = writer_capacity_df['Writer ID'].unique()\n",
        "    campaigns = contracted_approved_df['Campaign ID'].unique()\n",
        "\n",
        "    print(f\"Optimization: {len(writers)} writers, {len(campaigns)} campaigns\")\n",
        "\n",
        "    if len(writers) == 0 or len(campaigns) == 0:\n",
        "        return None, \"No writers or campaigns found.\"\n",
        "\n",
        "    priority_weights = get_campaign_priority_weights(contracted_approved_df)\n",
        "\n",
        "    # First Time Cycle targets\n",
        "    first_time_targets = {}\n",
        "    for _, campaign_row in contracted_approved_df.iterrows():\n",
        "        campaign = campaign_row['Campaign ID']\n",
        "        if 'First Time Cycle' in campaign_row:\n",
        "            first_time_value = str(campaign_row['First Time Cycle']).strip().lower()\n",
        "            if first_time_value in ['yes', 'true', '1']:\n",
        "                outstanding = campaign_row.get('Outstanding on day', 0)\n",
        "                topics_approved = campaign_row.get('Topics Approved', 0)\n",
        "                if pd.notna(outstanding) and pd.notna(topics_approved) and topics_approved > 0:\n",
        "                    assignable_content = min(outstanding, topics_approved)\n",
        "                    target = min(13, int(assignable_content / 2.5))\n",
        "                    first_time_targets[campaign] = target\n",
        "\n",
        "    # Variables\n",
        "    article_count = {}\n",
        "    for writer in writers:\n",
        "        for campaign in campaigns:\n",
        "            article_count[(writer, campaign)] = solver.IntVar(0, 1000, f'count_{writer}_{campaign}')\n",
        "\n",
        "    # Writer capacity constraints\n",
        "    for writer in writers:\n",
        "        writer_rows = writer_capacity_df[writer_capacity_df['Writer ID'] == writer]\n",
        "        if not writer_rows.empty:\n",
        "            capacity = writer_rows['Weekly Capacity'].iloc[0]\n",
        "            if pd.notna(capacity):\n",
        "                solver.Add(sum(article_count[(writer, campaign)] for campaign in campaigns) <= capacity)\n",
        "\n",
        "    # Campaign constraints\n",
        "    for campaign in campaigns:\n",
        "        campaign_rows = contracted_approved_df[contracted_approved_df['Campaign ID'] == campaign]\n",
        "        if not campaign_rows.empty:\n",
        "            outstanding = campaign_rows['Outstanding on day'].fillna(0).iloc[0]\n",
        "            topics_approved = campaign_rows['Topics Approved'].fillna(0).iloc[0]\n",
        "\n",
        "            assignable_content = min(outstanding, topics_approved) if topics_approved > 0 else 0\n",
        "\n",
        "            if assignable_content > 0:\n",
        "                solver.Add(sum(article_count[(writer, campaign)] for writer in writers) <= assignable_content)\n",
        "\n",
        "                if campaign in first_time_targets:\n",
        "                    solver.Add(sum(article_count[(writer, campaign)] for writer in writers) >= first_time_targets[campaign])\n",
        "                else:\n",
        "                    solver.Add(sum(article_count[(writer, campaign)] for writer in writers) >= min(3, assignable_content))\n",
        "            else:\n",
        "                for writer in writers:\n",
        "                    solver.Add(article_count[(writer, campaign)] == 0)\n",
        "\n",
        "    # Objective function\n",
        "    objective = solver.Objective()\n",
        "    faced_writer_col = next((col for col in campaign_writer_df.columns if 'faced' in col.lower() and 'writer' in col.lower()), 'Faced Writer')\n",
        "\n",
        "    for writer in writers:\n",
        "        for campaign in campaigns:\n",
        "            base_weight = 0.1\n",
        "\n",
        "            context_row = campaign_writer_df[\n",
        "                (campaign_writer_df['Writer ID'].str.lower() == str(writer).lower()) &\n",
        "                (campaign_writer_df['Campaign ID'] == campaign)\n",
        "            ]\n",
        "\n",
        "            if not context_row.empty:\n",
        "                base_weight = 1.0\n",
        "\n",
        "                # Faced writer bonus\n",
        "                if faced_writer_col in context_row.columns:\n",
        "                    try:\n",
        "                        if bool(context_row.iloc[0][faced_writer_col]):\n",
        "                            base_weight *= 15\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                # Context score bonus\n",
        "                if 'Context Score' in context_row.columns:\n",
        "                    try:\n",
        "                        context_score = context_row.iloc[0]['Context Score']\n",
        "                        if pd.notna(context_score):\n",
        "                            base_weight *= (1 + float(context_score) * 10)\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "            base_weight *= priority_weights.get(campaign, 1.0)\n",
        "            objective.SetCoefficient(article_count[(writer, campaign)], base_weight)\n",
        "\n",
        "    objective.SetMaximization()\n",
        "\n",
        "    print(\"Solving optimization...\")\n",
        "    status = solver.Solve()\n",
        "\n",
        "    if status != pywraplp.Solver.OPTIMAL:\n",
        "        return None, \"Optimization failed\"\n",
        "\n",
        "    # Collect results\n",
        "    assignments = []\n",
        "    current_time = datetime.now()\n",
        "\n",
        "    for writer in writers:\n",
        "        for campaign in campaigns:\n",
        "            count_value = article_count[(writer, campaign)].solution_value()\n",
        "            if count_value > 0:\n",
        "                campaign_data = contracted_approved_df[contracted_approved_df['Campaign ID'] == campaign]\n",
        "                context_row = campaign_writer_df[\n",
        "                    (campaign_writer_df['Writer ID'].str.lower() == str(writer).lower()) &\n",
        "                    (campaign_writer_df['Campaign ID'] == campaign)\n",
        "                ]\n",
        "\n",
        "                campaign_url = \"\"\n",
        "                next_billing_date = None\n",
        "                is_first_time_cycle = False\n",
        "                faced_writer = False\n",
        "                context_score = None\n",
        "\n",
        "                if not campaign_data.empty:\n",
        "                    if 'URL' in campaign_data.columns:\n",
        "                        url_value = campaign_data['URL'].iloc[0]\n",
        "                        campaign_url = str(url_value) if pd.notna(url_value) else \"\"\n",
        "\n",
        "                    if 'Next Billing Date' in campaign_data.columns:\n",
        "                        billing_str = campaign_data['Next Billing Date'].iloc[0]\n",
        "                        if pd.notna(billing_str) and str(billing_str).strip():\n",
        "                            try:\n",
        "                                next_billing_date = pd.to_datetime(billing_str).date()\n",
        "                            except:\n",
        "                                pass\n",
        "\n",
        "                    if 'First Time Cycle' in campaign_data.columns:\n",
        "                        first_time_value = str(campaign_data['First Time Cycle'].iloc[0]).strip().lower()\n",
        "                        is_first_time_cycle = first_time_value in ['yes', 'true', '1']\n",
        "\n",
        "                if not context_row.empty:\n",
        "                    if faced_writer_col in context_row.columns:\n",
        "                        try:\n",
        "                            faced_value = context_row.iloc[0][faced_writer_col]\n",
        "                            faced_writer = bool(faced_value)\n",
        "                        except:\n",
        "                            pass\n",
        "                    if 'Context Score' in context_row.columns:\n",
        "                        try:\n",
        "                            score_value = context_row.iloc[0]['Context Score']\n",
        "                            if pd.notna(score_value):\n",
        "                                context_score = float(score_value)\n",
        "                        except:\n",
        "                            pass\n",
        "\n",
        "                assignments.append({\n",
        "                    'campaign_id': campaign,\n",
        "                    'campaign_url': campaign_url,\n",
        "                    'writer_id': writer,\n",
        "                    'weekly_target': int(count_value),\n",
        "                    'is_faced_writer': faced_writer,\n",
        "                    'is_first_time_cycle': is_first_time_cycle,\n",
        "                    'context_score': context_score,\n",
        "                    'next_billing_date': next_billing_date,\n",
        "                    'assignment_date': current_time.date(),\n",
        "                    'created_at': current_time,\n",
        "                    'updated_at': current_time\n",
        "                })\n",
        "\n",
        "    assignments_df = pd.DataFrame(assignments)\n",
        "    print(f\"Created {len(assignments_df)} assignments, {assignments_df['weekly_target'].sum()} total articles\")\n",
        "\n",
        "    first_time_count = assignments_df[assignments_df['is_first_time_cycle']]['weekly_target'].sum()\n",
        "    if first_time_count > 0:\n",
        "        print(f\"First Time Cycle: {first_time_count} articles\")\n",
        "\n",
        "    return assignments_df, \"\"\n",
        "\n",
        "def create_table_if_not_exists():\n",
        "    \"\"\"Create/update the table if needed\"\"\"\n",
        "    try:\n",
        "        conn = psycopg2.connect(**pg_params)\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Add is_latest column if it doesn't exist\n",
        "        cursor.execute(\"\"\"\n",
        "            ALTER TABLE gist.csmmailer_fridayallocation\n",
        "            ADD COLUMN IF NOT EXISTS is_latest BOOLEAN DEFAULT FALSE;\n",
        "        \"\"\")\n",
        "\n",
        "        # Create index if it doesn't exist\n",
        "        cursor.execute(\"\"\"\n",
        "            CREATE INDEX IF NOT EXISTS idx_fridayallocation_is_latest\n",
        "            ON gist.csmmailer_fridayallocation(is_latest);\n",
        "        \"\"\")\n",
        "\n",
        "        conn.commit()\n",
        "        cursor.close()\n",
        "        conn.close()\n",
        "        print(\"✅ Table updated successfully\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error updating table: {e}\")\n",
        "        return False\n",
        "\n",
        "def insert_to_postgres(assignments_df):\n",
        "    \"\"\"Insert assignment data to PostgreSQL with latest flag tracking\"\"\"\n",
        "    if assignments_df is None or assignments_df.empty:\n",
        "        print(\"❌ No data to insert\")\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        engine = create_engine(f\"postgresql://{pg_params['user']}:{pg_params['password']}@{pg_params['host']}:{pg_params['port']}/{pg_params['database']}\")\n",
        "\n",
        "        current_run_time = datetime.now()\n",
        "        assignments_df = assignments_df.copy()\n",
        "        assignments_df['run_timestamp'] = current_run_time\n",
        "        assignments_df['is_latest'] = True\n",
        "\n",
        "        # Update previous records\n",
        "        with engine.connect() as conn:\n",
        "            conn.execute(text(\"UPDATE gist.csmmailer_fridayallocation SET is_latest = FALSE WHERE is_latest = TRUE\"))\n",
        "            conn.commit()\n",
        "\n",
        "        # Data type conversions\n",
        "        assignments_df['weekly_target'] = assignments_df['weekly_target'].astype(int)\n",
        "        assignments_df['is_faced_writer'] = assignments_df['is_faced_writer'].astype(bool)\n",
        "        assignments_df['is_first_time_cycle'] = assignments_df['is_first_time_cycle'].astype(bool)\n",
        "        assignments_df['is_latest'] = assignments_df['is_latest'].astype(bool)\n",
        "        assignments_df['context_score'] = assignments_df['context_score'].replace({np.nan: None})\n",
        "\n",
        "        if 'next_billing_date' in assignments_df.columns:\n",
        "            assignments_df['next_billing_date'] = pd.to_datetime(assignments_df['next_billing_date'], errors='coerce').dt.date\n",
        "\n",
        "        assignments_df['assignment_date'] = pd.to_datetime(assignments_df['assignment_date']).dt.date\n",
        "        assignments_df['created_at'] = pd.to_datetime(assignments_df['created_at'])\n",
        "        assignments_df['updated_at'] = pd.to_datetime(assignments_df['updated_at'])\n",
        "\n",
        "        print(f\"📊 Inserting {len(assignments_df)} records at {current_run_time}\")\n",
        "\n",
        "        assignments_df.to_sql(\n",
        "            name='csmmailer_fridayallocation',\n",
        "            con=engine,\n",
        "            schema='gist',\n",
        "            if_exists='append',\n",
        "            index=False,\n",
        "            method='multi'\n",
        "        )\n",
        "\n",
        "        # Summary stats\n",
        "        with engine.connect() as conn:\n",
        "            total_records = conn.execute(text(\"SELECT COUNT(*) FROM gist.csmmailer_fridayallocation\")).scalar()\n",
        "            latest_records = conn.execute(text(\"SELECT COUNT(*) FROM gist.csmmailer_fridayallocation WHERE is_latest = TRUE\")).scalar()\n",
        "\n",
        "            print(f\"✅ Success! Total records: {total_records}, Latest: {latest_records}\")\n",
        "\n",
        "        engine.dispose()\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Insert error: {e}\")\n",
        "        return False\n",
        "\n",
        "def get_recent_runs(limit=3):\n",
        "    \"\"\"Get summary of recent optimization runs\"\"\"\n",
        "    try:\n",
        "        engine = create_engine(f\"postgresql://{pg_params['user']}:{pg_params['password']}@{pg_params['host']}:{pg_params['port']}/{pg_params['database']}\")\n",
        "\n",
        "        query = f\"\"\"\n",
        "        SELECT run_timestamp, COUNT(*) as assignments, SUM(weekly_target) as articles,\n",
        "               MAX(CASE WHEN is_latest THEN 1 ELSE 0 END) as is_latest\n",
        "        FROM gist.csmmailer_fridayallocation\n",
        "        GROUP BY run_timestamp\n",
        "        ORDER BY run_timestamp DESC\n",
        "        LIMIT {limit}\n",
        "        \"\"\"\n",
        "\n",
        "        df = pd.read_sql(query, engine)\n",
        "\n",
        "        if not df.empty:\n",
        "            print(f\"\\n📋 Recent Runs:\")\n",
        "            for _, row in df.iterrows():\n",
        "                indicator = \"🟢 LATEST\" if row['is_latest'] else \"🔴\"\n",
        "                print(f\"{row['run_timestamp']} {indicator} - {row['assignments']} assignments, {row['articles']} articles\")\n",
        "\n",
        "        engine.dispose()\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error getting runs: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the complete writer assignment system\"\"\"\n",
        "    print(\"=== Friday Writer Allocation System ===\")\n",
        "\n",
        "    # Google Sheets authentication (only for writer capacity)\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = default()\n",
        "    gc = gspread.authorize(creds)\n",
        "\n",
        "    # Load data - contracted and context from PostgreSQL, capacity from Google Sheets\n",
        "    capacity_sheet = '1QPGzI73Ma0qbsbBpiucsJSX2ikmY_i4FKqIJ9OnWFw0'\n",
        "\n",
        "    print(\"Loading data...\")\n",
        "    contracted_df = read_postgres_table('gist.writerallocation_contractedapproved')\n",
        "    campaign_writer_df = read_postgres_table('gist.writerallocation_contexttable')\n",
        "    writer_capacity_df = read_google_sheet(gc, capacity_sheet)\n",
        "\n",
        "    # Check data availability\n",
        "    if contracted_df.empty or campaign_writer_df.empty or writer_capacity_df.empty:\n",
        "        print(\"❌ Missing required data from sources\")\n",
        "        return None\n",
        "\n",
        "    # Standardize writer IDs\n",
        "    if 'Writer ID' in campaign_writer_df.columns:\n",
        "        campaign_writer_df['Writer ID'] = campaign_writer_df['Writer ID'].astype(str).str.lower()\n",
        "    if 'writer_id' in campaign_writer_df.columns:\n",
        "        campaign_writer_df['writer_id'] = campaign_writer_df['writer_id'].astype(str).str.lower()\n",
        "        campaign_writer_df['Writer ID'] = campaign_writer_df['writer_id']\n",
        "\n",
        "    if 'Writer ID' in writer_capacity_df.columns:\n",
        "        writer_capacity_df['Writer ID'] = writer_capacity_df['Writer ID'].astype(str).str.lower()\n",
        "    if 'writer_id' in writer_capacity_df.columns:\n",
        "        writer_capacity_df['writer_id'] = writer_capacity_df['writer_id'].astype(str).str.lower()\n",
        "        writer_capacity_df['Writer ID'] = writer_capacity_df['writer_id']\n",
        "\n",
        "    # Standardize campaign IDs\n",
        "    if 'Campaign ID' in contracted_df.columns:\n",
        "        pass\n",
        "    elif 'campaign_id' in contracted_df.columns:\n",
        "        contracted_df['Campaign ID'] = contracted_df['campaign_id']\n",
        "\n",
        "    if 'Campaign ID' in campaign_writer_df.columns:\n",
        "        pass\n",
        "    elif 'campaign_id' in campaign_writer_df.columns:\n",
        "        campaign_writer_df['Campaign ID'] = campaign_writer_df['campaign_id']\n",
        "\n",
        "    # Filter active campaigns - adapt to PostgreSQL column names\n",
        "    status_col = 'Status' if 'Status' in contracted_df.columns else 'status'\n",
        "    type_col = 'Type' if 'Type' in contracted_df.columns else 'type'\n",
        "\n",
        "    if status_col in contracted_df.columns and type_col in contracted_df.columns:\n",
        "        contracted_df = contracted_df[\n",
        "            (contracted_df[status_col] == 'Active') &\n",
        "            (contracted_df[type_col] == 'Product')\n",
        "        ]\n",
        "        print(f\"Active campaigns: {len(contracted_df)}\")\n",
        "\n",
        "    # Standardize column names for required columns\n",
        "    column_mapping = {\n",
        "        'campaign_id': 'Campaign ID',\n",
        "        'url': 'URL',\n",
        "        'topics_approved': 'Topics Approved',\n",
        "        'outstanding_on_day': 'Outstanding on day',\n",
        "        'next_billing_date': 'Next Billing Date',\n",
        "        'first_time_cycle': 'First Time Cycle'\n",
        "    }\n",
        "\n",
        "    for pg_col, std_col in column_mapping.items():\n",
        "        if pg_col in contracted_df.columns and std_col not in contracted_df.columns:\n",
        "            contracted_df[std_col] = contracted_df[pg_col]\n",
        "\n",
        "    # Standardize context table column names\n",
        "    context_column_mapping = {\n",
        "        'writer_id': 'Writer ID',\n",
        "        'campaign_id': 'Campaign ID',\n",
        "        'faced_writer': 'Faced Writer',\n",
        "        'context_score': 'Context Score'\n",
        "    }\n",
        "\n",
        "    for pg_col, std_col in context_column_mapping.items():\n",
        "        if pg_col in campaign_writer_df.columns and std_col not in campaign_writer_df.columns:\n",
        "            campaign_writer_df[std_col] = campaign_writer_df[pg_col]\n",
        "\n",
        "    # Standardize capacity table column names\n",
        "    capacity_column_mapping = {\n",
        "        'writer_id': 'Writer ID',\n",
        "        'weekly_capacity': 'Weekly Capacity'\n",
        "    }\n",
        "\n",
        "    for pg_col, std_col in capacity_column_mapping.items():\n",
        "        if pg_col in writer_capacity_df.columns and std_col not in writer_capacity_df.columns:\n",
        "            writer_capacity_df[std_col] = writer_capacity_df[pg_col]\n",
        "\n",
        "    # Add missing columns if needed\n",
        "    required_cols = ['Campaign ID', 'URL', 'Topics Approved', 'Outstanding on day', 'Next Billing Date', 'First Time Cycle']\n",
        "    for col in required_cols:\n",
        "        if col not in contracted_df.columns:\n",
        "            if col in ['Next Billing Date', 'URL']:\n",
        "                contracted_df[col] = \"\"\n",
        "            elif col == 'First Time Cycle':\n",
        "                contracted_df[col] = \"No\"\n",
        "            else:\n",
        "                contracted_df[col] = 0\n",
        "\n",
        "    # Convert numeric columns\n",
        "    for col in ['Topics Approved', 'Outstanding on day']:\n",
        "        if col in contracted_df.columns:\n",
        "            contracted_df[col] = pd.to_numeric(contracted_df[col], errors='coerce').fillna(0)\n",
        "\n",
        "    # Filter active writers\n",
        "    active_writers_df = writer_capacity_df[writer_capacity_df['Weekly Capacity'] > 0].copy()\n",
        "\n",
        "    # Run optimization\n",
        "    assignments_df, error = optimize_writer_assignments(contracted_df, campaign_writer_df, active_writers_df)\n",
        "\n",
        "    if assignments_df is not None:\n",
        "        # Setup database and insert\n",
        "        if create_table_if_not_exists():\n",
        "            get_recent_runs()\n",
        "            success = insert_to_postgres(assignments_df)\n",
        "            if success:\n",
        "                get_recent_runs()\n",
        "                return assignments_df\n",
        "\n",
        "    print(f\"ERROR: {error}\")\n",
        "    return None\n",
        "\n",
        "# Run the system\n",
        "if __name__ == \"__main__\":\n",
        "    result = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP2_wiNyEOv5",
        "outputId": "09ade60e-7030-4dfd-9f58-1fb59b2d7712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Friday Writer Allocation System ===\n",
            "Loading data...\n",
            "✅ Loaded 161 records from gist.writerallocation_contractedapproved\n",
            "✅ Loaded 854 records from gist.writerallocation_contexttable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-17-3952639557.py:43: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Active campaigns: 131\n",
            "Optimization: 68 writers, 131 campaigns\n",
            "Campaign 0351b0fe-1ee7-4d78-827d-8c08e33a0b86 is First Time Cycle - applying 20x priority\n",
            "Campaign 384c5612-722b-43d8-95c9-2c50247c6a93 is First Time Cycle - applying 20x priority\n",
            "Campaign 5f2ed42c-58e8-402e-8d8c-aff56b958c6b is First Time Cycle - applying 20x priority\n",
            "Campaign 61f708d1-7421-4ffb-a3be-0967aa4b072c is First Time Cycle - applying 20x priority\n",
            "Campaign 72663ba7-3e84-4204-a72f-7fce50607eea is First Time Cycle - applying 20x priority\n",
            "Campaign 80612b3f-ea4b-4bd7-99b7-37a1421fafc1 is First Time Cycle - applying 20x priority\n",
            "Campaign 89349814-59d2-477c-8b56-9c9d471e7f9e is First Time Cycle - applying 20x priority\n",
            "Campaign a8998f69-bb75-4b2e-9d80-5e9815533ecb is First Time Cycle - applying 20x priority\n",
            "Campaign b4154640-a977-4927-8bd0-932154cfca90 is First Time Cycle - applying 20x priority\n",
            "Campaign b439f3cf-5b49-455b-b9e5-5f1c90f34772 is First Time Cycle - applying 20x priority\n",
            "Campaign be966cd9-ba2f-4ef9-b435-2a2a9728b49f is First Time Cycle - applying 20x priority\n",
            "Campaign e29c6a96-66e9-4fee-9dff-bc16172669e6 is First Time Cycle - applying 20x priority\n",
            "Solving optimization...\n",
            "Created 170 assignments, 680 total articles\n",
            "First Time Cycle: 117 articles\n",
            "✅ Table updated successfully\n",
            "📊 Inserting 170 records at 2025-06-19 07:44:37.636326\n",
            "✅ Success! Total records: 170, Latest: 170\n",
            "\n",
            "📋 Recent Runs:\n",
            "2025-06-19 07:44:37.636326 🟢 LATEST - 170 assignments, 680 articles\n"
          ]
        }
      ]
    }
  ]
}