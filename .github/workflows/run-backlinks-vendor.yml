name: Run Backlinks Vendor Import

on:
  workflow_dispatch: {}
  schedule:
    - cron: '*/3 * * * *'   # every 3 minutes (UTC)

concurrency:
  group: backlinks-vendor-import
  cancel-in-progress: true   # cancel prior run if a new one starts

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          pip install --upgrade pip
          pip install pandas sqlalchemy psycopg2-binary papermill jupyter

      - name: Execute notebook with papermill
        env:
          DB_URL: ${{ secrets.POSTGRES_DB_URL }}
        run: |
          mkdir -p artifacts
          papermill "gist_daily_runs/Backlinks_data_from_vendor_Manufacturing.ipynb" \
                   "artifacts/Backlinks_data_from_vendor_Manufacturing.out.ipynb" -k python3

      - name: Upload executed notebook
        uses: actions/upload-artifact@v4
        with:
          name: backlinks-vendor-run
          path: artifacts/Backlinks_data_from_vendor_Manufacturing.out.ipynb
