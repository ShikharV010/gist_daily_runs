{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmsGiA7rdineKw40Qzbc42",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShikharV010/gist_daily_runs/blob/main/PagePerformance_TrendsCalculations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xRvGh0CSUek",
        "outputId": "fb894d74-1029-4d40-b89c-5d8bc7273d69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.41)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.2.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (4.14.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
            "Successfully installed psycopg2-binary-2.9.10\n"
          ]
        }
      ],
      "source": [
        "!pip install psycopg2-binary sqlalchemy pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Replace with your actual PostgreSQL connection info\n",
        "db_config = {\n",
        "    'user': 'airbyte_user',\n",
        "    'password': 'airbyte_user_password',\n",
        "    'host': 'gw-postgres-dev.celzx4qnlkfp.us-east-1.rds.amazonaws.com',\n",
        "    'port': '5432',\n",
        "    'database': 'gw_prod'\n",
        "}\n",
        "\n",
        "# Create SQLAlchemy engine\n",
        "engine = create_engine(f\"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\")\n"
      ],
      "metadata": {
        "id": "VsJ-jzF9Sw0i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql = \"\"\"\n",
        "SELECT\n",
        "  campaign_id,\n",
        "  start_date::date AS start_date,\n",
        "  end_date::date AS end_date,\n",
        "  impressions,\n",
        "  clicks,\n",
        "  ctr,\n",
        "  position\n",
        "FROM gist.matv_gist_pageperformance\n",
        "\"\"\"\n",
        "df_raw = pd.read_sql(sql, engine)\n"
      ],
      "metadata": {
        "id": "vwGmcWRwV88X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get distinct weeks sorted by start_date\n",
        "week_ranks = (\n",
        "    df_raw[['start_date', 'end_date']]\n",
        "    .drop_duplicates()\n",
        "    .sort_values('start_date')\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "week_ranks['week_no'] = week_ranks.reset_index().index + 1  # earliest = 1\n",
        "\n",
        "# Merge back into raw data\n",
        "df_ranked = df_raw.merge(week_ranks, on=['start_date', 'end_date'], how='left')\n"
      ],
      "metadata": {
        "id": "kr9Wq9iSahyM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_agg = (\n",
        "    df_ranked\n",
        "    .groupby(['campaign_id', 'week_no'], as_index=False)\n",
        "    .agg({\n",
        "        'impressions': 'sum',\n",
        "        'clicks': 'sum',\n",
        "        'ctr': 'mean',          # You can change to weighted avg later\n",
        "        'position': lambda x: x.replace(0, np.nan).mean()\n",
        "    })\n",
        ")\n"
      ],
      "metadata": {
        "id": "SqSxT0CooIGf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pivot = df_agg.pivot(index='campaign_id', columns='week_no')\n",
        "\n",
        "# Flatten multi-index columns like ('clicks', 12) → clicks_week_12\n",
        "df_pivot.columns = [\n",
        "    f\"{metric}_week_{week_no}\" for metric, week_no in df_pivot.columns\n",
        "]\n",
        "df_pivot.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "Sli4yQFpoo1w"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Helper function\n",
        "def get_trend_label(metric, change):\n",
        "    metric = metric.rstrip(\"s\")  # Ensure labels say \"impression\" not \"impressions\"\n",
        "    if change > 0.30: return f\"{metric} gain > 30%\"\n",
        "    elif change > 0.20: return f\"{metric} gain > 20%\"\n",
        "    elif change > 0.10: return f\"{metric} gain > 10%\"\n",
        "    elif change > 0.05: return f\"{metric} gain > 5%\"\n",
        "    elif change < -0.30: return f\"{metric} drop > 30%\"\n",
        "    elif change < -0.20: return f\"{metric} drop > 20%\"\n",
        "    elif change < -0.10: return f\"{metric} drop > 10%\"\n",
        "    elif change < -0.05: return f\"{metric} drop > 5%\"\n",
        "    return \"\"\n",
        "\n",
        "# 2. Get week numbers from columns\n",
        "week_nums = sorted([\n",
        "    int(col.split(\"_week_\")[1])\n",
        "    for col in df_pivot.columns\n",
        "    if \"_week_\" in col and col.startswith(\"impressions\")\n",
        "], reverse=True)\n",
        "\n",
        "# 3. Pick top 10 latest week pairs\n",
        "latest_weeks = week_nums[:11]  # 11 weeks to do 10 comparisons\n",
        "\n",
        "# 4. Initialize output container\n",
        "performance_columns = {\"campaign_id\": df_pivot[\"campaign_id\"]}\n",
        "\n",
        "# 5. Loop through and calculate\n",
        "for i in range(1, 11):\n",
        "    week_n = latest_weeks[i - 1]      # current week\n",
        "    week_prev = latest_weeks[i]       # previous week\n",
        "\n",
        "    label_list = []\n",
        "\n",
        "    for metric in [\"impressions\", \"clicks\", \"ctr\"]:\n",
        "        col_curr = f\"{metric}_week_{week_n}\"\n",
        "        col_prev = f\"{metric}_week_{week_prev}\"\n",
        "\n",
        "        change = (\n",
        "            (df_pivot[col_curr] - df_pivot[col_prev]) / df_pivot[col_prev]\n",
        "        ).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "        label_series = change.apply(lambda x: get_trend_label(metric, x))\n",
        "        label_list.append(label_series)\n",
        "\n",
        "    # Combine all metric labels for this comparison\n",
        "    combined = pd.DataFrame(label_list).T\n",
        "    combined[f\"performance_week_{week_n}\"] = combined.apply(\n",
        "        lambda row: \"Stagnant\" if all(v == \"\" for v in row) else \", \".join(filter(None, row)),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    performance_columns[f\"performance_week_{week_n}\"] = combined[f\"performance_week_{week_n}\"]\n",
        "\n",
        "# 6. Final weekly performance DataFrame\n",
        "df_weekly_perf = pd.DataFrame(performance_columns)\n"
      ],
      "metadata": {
        "id": "QNpDKY5Hp7Q5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_labels = []\n",
        "\n",
        "# Dynamically extract top 8 week numbers (latest first)\n",
        "week_nums = sorted([\n",
        "    int(col.split(\"_week_\")[1])\n",
        "    for col in df_pivot.columns\n",
        "    if col.startswith(\"impressions_week_\")\n",
        "], reverse=True)\n",
        "\n",
        "recent_4 = week_nums[:4]\n",
        "past_4 = week_nums[4:8]\n",
        "\n",
        "for _, row in df_pivot.iterrows():\n",
        "    labels = []\n",
        "\n",
        "    # Sum recent and past impressions\n",
        "    recent_impr = row[[f\"impressions_week_{w}\" for w in recent_4 if f\"impressions_week_{w}\" in row]].sum()\n",
        "    past_impr = row[[f\"impressions_week_{w}\" for w in past_4 if f\"impressions_week_{w}\" in row]].sum()\n",
        "\n",
        "    # Sum clicks\n",
        "    recent_clicks = row[[f\"clicks_week_{w}\" for w in recent_4 if f\"clicks_week_{w}\" in row]].sum()\n",
        "    past_clicks = row[[f\"clicks_week_{w}\" for w in past_4 if f\"clicks_week_{w}\" in row]].sum()\n",
        "\n",
        "    # Average CTR\n",
        "    recent_ctr = row[[f\"ctr_week_{w}\" for w in recent_4 if f\"ctr_week_{w}\" in row]].mean()\n",
        "    past_ctr = row[[f\"ctr_week_{w}\" for w in past_4 if f\"ctr_week_{w}\" in row]].mean()\n",
        "\n",
        "    # Generate performance label\n",
        "    for metric, recent, past in zip(\n",
        "        [\"impression\", \"clicks\", \"ctr\"],\n",
        "        [recent_impr, recent_clicks, recent_ctr],\n",
        "        [past_impr, past_clicks, past_ctr]\n",
        "    ):\n",
        "        change = 0 if past == 0 else (recent - past) / past\n",
        "        label = get_trend_label(metric, change)\n",
        "        if label:\n",
        "            labels.append(label)\n",
        "\n",
        "    final_label = \"Stagnant\" if not labels else \", \".join(labels)\n",
        "    monthly_labels.append(final_label)\n",
        "\n",
        "# Final DataFrame\n",
        "df_monthly_perf = pd.DataFrame({\n",
        "    \"campaign_id\": df_pivot[\"campaign_id\"],\n",
        "    \"performance_monthly\": monthly_labels\n",
        "})\n"
      ],
      "metadata": {
        "id": "tUSbFpoKp-E7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quarterly_labels = []\n",
        "\n",
        "# Get valid weeks where all required metrics are present\n",
        "valid_weeks = [\n",
        "    w for w in week_nums\n",
        "    if all(f\"{metric}_week_{w}\" in df_pivot.columns for metric in [\"impressions\", \"clicks\", \"ctr\"])\n",
        "]\n",
        "\n",
        "if len(valid_weeks) >= 13:  # Minimum 13 to allow a gap and at least 1 past week\n",
        "    latest_week = valid_weeks[0]\n",
        "\n",
        "    # Current quarter: latest 12 weeks\n",
        "    recent_12 = [latest_week - i for i in range(12)]\n",
        "\n",
        "    # For past quarter: up to 12 weeks before the recent block, skip 1 week in between\n",
        "    past_start = latest_week - 13\n",
        "    past_weeks = [past_start - i for i in range(12)]\n",
        "    past_weeks_available = [w for w in past_weeks if w in valid_weeks]\n",
        "\n",
        "    for _, row in df_pivot.iterrows():\n",
        "        labels = []\n",
        "\n",
        "        # Aggregate recent quarter\n",
        "        recent_impr = row[[f\"impressions_week_{w}\" for w in recent_12 if f\"impressions_week_{w}\" in row]].sum()\n",
        "        past_impr = row[[f\"impressions_week_{w}\" for w in past_weeks_available if f\"impressions_week_{w}\" in row]].sum()\n",
        "\n",
        "        recent_clicks = row[[f\"clicks_week_{w}\" for w in recent_12 if f\"clicks_week_{w}\" in row]].sum()\n",
        "        past_clicks = row[[f\"clicks_week_{w}\" for w in past_weeks_available if f\"clicks_week_{w}\" in row]].sum()\n",
        "\n",
        "        recent_ctr = row[[f\"ctr_week_{w}\" for w in recent_12 if f\"ctr_week_{w}\" in row]].mean()\n",
        "        past_ctr = row[[f\"ctr_week_{w}\" for w in past_weeks_available if f\"ctr_week_{w}\" in row]].mean()\n",
        "\n",
        "        for metric, recent, past in zip(\n",
        "            [\"impression\", \"clicks\", \"ctr\"],\n",
        "            [recent_impr, recent_clicks, recent_ctr],\n",
        "            [past_impr, past_clicks, past_ctr]\n",
        "        ):\n",
        "            change = 0 if past == 0 else (recent - past) / past\n",
        "            label = get_trend_label(metric, change)\n",
        "            if label:\n",
        "                labels.append(label)\n",
        "\n",
        "        final = \"Stagnant\" if not labels else \", \".join(labels)\n",
        "        quarterly_labels.append(final)\n",
        "\n",
        "    df_quarterly_perf = pd.DataFrame({\n",
        "        \"campaign_id\": df_pivot[\"campaign_id\"],\n",
        "        \"performance_quarterly\": quarterly_labels\n",
        "    })\n",
        "\n",
        "else:\n",
        "    print(\"Not enough weeks to compute quarterly performance (need ≥13 weeks)\")\n",
        "    df_quarterly_perf = pd.DataFrame({\n",
        "        \"campaign_id\": df_pivot[\"campaign_id\"],\n",
        "        \"performance_quarterly\": [\"N/A\"] * len(df_pivot)\n",
        "    })\n"
      ],
      "metadata": {
        "id": "K3Xc5bzk3CYy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge on campaign_id\n",
        "df_perf_all = df_monthly_perf.merge(df_quarterly_perf, on=\"campaign_id\", how=\"left\") \\\n",
        "                             .merge(df_weekly_perf, on=\"campaign_id\", how=\"left\")\n",
        "\n",
        "# Show full DataFrame in notebook\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "PIvfMcdfZDnj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Identify only the performance_week_* columns\n",
        "week_perf_cols = [col for col in df_perf_all.columns if col.startswith(\"performance_week_\")]\n",
        "\n",
        "# Step 2: Extract week numbers and sort descending (latest week first)\n",
        "original_week_nums = sorted([\n",
        "    int(col.split(\"_\")[-1]) for col in week_perf_cols\n",
        "], reverse=True)\n",
        "\n",
        "# Step 3: Create a mapping to rename them with week_10 being latest\n",
        "rename_map = {\n",
        "    f\"performance_week_{old}\": f\"performance_week_{new}\"\n",
        "    for old, new in zip(original_week_nums, range(10, 0, -1))\n",
        "}\n",
        "\n",
        "# Step 4: Apply renaming to get the final DataFrame\n",
        "df_perf_all_final = df_perf_all.rename(columns=rename_map)\n"
      ],
      "metadata": {
        "id": "VJnq1YcRwPBJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all unique week numbers from impressions columns\n",
        "week_nums_all = sorted([\n",
        "    int(col.split(\"_week_\")[1])\n",
        "    for col in df_pivot.columns\n",
        "    if col.startswith(\"impressions_week_\")\n",
        "], reverse=True)\n",
        "\n",
        "# Take the top 10 weeks (most recent)\n",
        "top_10_weeks = week_nums_all[:10]\n",
        "\n",
        "# Desired order: first impressions for all weeks, then clicks, ctr, position\n",
        "metrics = ['impressions', 'clicks', 'ctr', 'position']\n",
        "ordered_cols = ['campaign_id'] + [\n",
        "    f\"{metric}_week_{w}\" for metric in metrics for w in top_10_weeks\n",
        "]\n",
        "\n",
        "# Filter the DataFrame\n",
        "df_pivot_filtered = df_pivot[ordered_cols].copy()\n"
      ],
      "metadata": {
        "id": "4Kkh5syP3QH_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a rename mapping: week_22 → week_10, week_21 → week_9, ..., week_13 → week_1\n",
        "rename_mapping = {}\n",
        "for i, week in enumerate(top_10_weeks):\n",
        "    for metric in metrics:\n",
        "        old_col = f\"{metric}_week_{week}\"\n",
        "        new_col = f\"{metric}_week_{10 - i}\"\n",
        "        rename_mapping[old_col] = new_col\n",
        "\n",
        "# Apply the renaming\n",
        "df_pivot_filtered_renamed = df_pivot_filtered.rename(columns=rename_mapping)\n"
      ],
      "metadata": {
        "id": "B-UN6we635cV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Join on campaign_id\n",
        "df_final = df_perf_all_final.merge(\n",
        "    df_pivot_filtered_renamed,\n",
        "    on='campaign_id',\n",
        "    how='left'\n",
        ")\n"
      ],
      "metadata": {
        "id": "7wUdhRaZ4GSs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "# Step 0: Setup engine\n",
        "engine = create_engine(\n",
        "    \"postgresql://airbyte_user:airbyte_user_password@gw-postgres-dev.celzx4qnlkfp.us-east-1.rds.amazonaws.com:5432/gw_prod\"\n",
        ")\n",
        "\n",
        "# Step 1: Force drop the materialized view WITH CASCADE\n",
        "with engine.begin() as conn:  # begin() ensures commit\n",
        "    print(\"⏳ Dropping materialized view...\")\n",
        "    conn.execute(text(\"DROP MATERIALIZED VIEW IF EXISTS gist.matv_gist_pageperformancetrends CASCADE;\"))\n",
        "    print(\"✅ Dropped materialized view\")\n",
        "\n",
        "# Step 2: Replace the base table\n",
        "df_final.to_sql(\n",
        "    name=\"gist_pageperformancetrends\",\n",
        "    con=engine,\n",
        "    schema=\"gist\",\n",
        "    if_exists=\"replace\",  # Replace table\n",
        "    index=False,\n",
        "    method=\"multi\"\n",
        ")\n",
        "print(\"✅ Table 'gist_pageperformancetrends' written successfully\")\n",
        "\n",
        "# Step 3: Recreate the materialized view (adjust if needed)\n",
        "with engine.begin() as conn:\n",
        "    print(\"⏳ Creating materialized view...\")\n",
        "    conn.execute(text(\"\"\"\n",
        "        CREATE MATERIALIZED VIEW gist.matv_gist_pageperformancetrends\n",
        "        TABLESPACE pg_default\n",
        "        AS\n",
        "        SELECT * FROM gist.gist_pageperformancetrends\n",
        "        WITH DATA;\n",
        "    \"\"\"))\n",
        "    conn.execute(text(\"ALTER TABLE gist.matv_gist_pageperformancetrends OWNER TO airbyte_user;\"))\n",
        "    print(\"✅ Recreated materialized view\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bO7ifpw0-gXP",
        "outputId": "5fb0291e-a262-4e15-b353-97da617f26dc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Dropping materialized view...\n",
            "✅ Dropped materialized view\n",
            "✅ Table 'gist_pageperformancetrends' written successfully\n",
            "⏳ Creating materialized view...\n",
            "✅ Recreated materialized view\n"
          ]
        }
      ]
    }
  ]
}